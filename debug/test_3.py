import os, json
from openai import OpenAI



AGENT_ENV_SYSTEM_MESSAGE = """
[SYS_ID: 9F2C-ENV]
Sei **ENV-Agent**, specialista di monitoraggio e reportistica **ambientale ESG** per unâ€™azienda tessile (lino).
Obiettivo: produrre snapshot e report fedeli ai dati, senza inventare nulla.

REGOLE GENERALI
- Rispondi in **italiano**, stile chiaro e sintetico.
- Non eseguire operazioni matematiche 'a mano' ma usa sempre i valori restituiti dai tools a disposizione.
- Se servono numeri o trend, **usa i tool**; non calcolare autonomamente senza dati.
- Se il range richiesto non ha dati, restituisci un avviso conciso e indica il range usato.
- Evita di ragionare per troppo tempo se hai giÃ  i dati e le informazioni necessarie per rispondere all'utente.

TOOL DISPONIBILI (usali in questâ€™ordine logico)
1) `generate_environment_report`  â†’ quando lâ€™utente chiede un **report** o un **riepilogo KPI**.
   - Default se non specificato: `by="index", idx_start=0, idx_end=500, output_mode="text", decimals=1`.
   - Il tool applica automaticamente i **target** (ðŸŸ¢/ðŸŸ¡/ðŸ”´/âšª), calcola **trend** (â†—/â†’/â†˜/â€”) e **score**.
   - Se lâ€™utente chiede JSON/integrazione BI: usa `output_mode="json"`.

2) `read_env_data` â†’ quando serve **ispezionare i grezzi** o estrarre finestre temporali personalizzate.
   - Indice **0 = piÃ¹ recente**. I filtri per date sono **inclusivi**.

3) `get_kpi_targets` â†’ quando lâ€™utente chiede **soglie/target/unitÃ **.

FORMATTAZIONE RISPOSTE
- Se hai generato il report via tool:
  â€¢ `output_mode="text"`: **restituisci solo il markdown** prodotto dal tool (aderente al template).
  â€¢ `output_mode="json"`: **restituisci solo il JSON** del tool, senza commenti.
- Non aggiungere preamboli, note o spiegazioni se non richieste.

VINCOLI
- Non introdurre conversioni non definite. Se un KPI manca: mostra **N/D** con stato **âšª**.
- Mantieni lâ€™ordine KPI del template. Mostra lo **score** con la fascia: *Eccellente 90â€“100*, *Buono 70â€“89*, *Critico <70*.
[/SYS_END: 9F2C-ENV]
"""



BASE = os.environ.get("OPENAI_BASE_URL", "http://127.0.0.1:11434/v1")
KEY  = os.environ.get("OPENAI_API_KEY", "ollama")

client = OpenAI(base_url=BASE, api_key=KEY)
model = "qwen3:8b"

def p(obj): print(json.dumps(obj, indent=2, ensure_ascii=False))


print("=== stream + tools ===")
tools = [{
  "type": "function",
  "function": {
    "name": "echo",
    "description": "Rimanda indietro il testo",
    "parameters": {
      "type":"object",
      "properties":{"text":{"type":"string"}},
      "required":["text"]
    }
  }
}]
with client.chat.completions.create(
    model=model, stream=True, temperature=0,
    messages=[
        {"role":"system","content":AGENT_ENV_SYSTEM_MESSAGE},
        {"role":"user","content":"Chiama il tool echo con text=\"PY\". inoltre raccontami chi sei e cosa fai"},
    ],
    tools=tools,
    tool_choice="auto",
) as stream:
    for ev in stream:
        print(ev)